{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ConcealGunDetection.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ieJ3fUl76CCb","colab_type":"text"},"source":["# Drive\n"]},{"cell_type":"code","metadata":{"id":"aygrRsHZd4UC","colab_type":"code","outputId":"8a526787-5bb4-4fda-e690-65237de5c98d","executionInfo":{"status":"ok","timestamp":1580444655942,"user_tz":-420,"elapsed":25316,"user":{"displayName":"PIMONPUN CHACHOMPHON","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mADcXHBbJOONF0InL7bXugUnPPUUcbPPNR_eEjaWy4=s64","userId":"14117620575648423760"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["from os.path import join\n","from google.colab import drive\n"," \n","ROOT = \"/content/drive\"\n","drive.mount(ROOT)\n"," \n","PROJ = \"My Drive/DetectConcealGun\" # This is a custom path.\n","PROJECT_PATH = join(ROOT, PROJ)\n"," \n","%cd ~/content\n","%cd drive/My Drive/DetectConcealGun"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","[Errno 2] No such file or directory: '/root/content'\n","/content\n","/content/drive/My Drive/DetectConcealGun\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hH4uKDxY19IV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"d626c829-52db-4384-8d18-7f38fef8806a","executionInfo":{"status":"ok","timestamp":1580444692535,"user_tz":-420,"elapsed":1183,"user":{"displayName":"PIMONPUN CHACHOMPHON","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mADcXHBbJOONF0InL7bXugUnPPUUcbPPNR_eEjaWy4=s64","userId":"14117620575648423760"}}},"source":["cd ep2/app"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/DetectConcealGun/ep2/app\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5-D03Yr72DXp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"ec1494ea-63da-4acd-de8c-0dfaf7683336","executionInfo":{"status":"ok","timestamp":1580444701022,"user_tz":-420,"elapsed":4750,"user":{"displayName":"PIMONPUN CHACHOMPHON","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mADcXHBbJOONF0InL7bXugUnPPUUcbPPNR_eEjaWy4=s64","userId":"14117620575648423760"}}},"source":["ls"],"execution_count":3,"outputs":[{"output_type":"stream","text":["admin_views.py   ConcealGunDetection.ipynb  \u001b[0m\u001b[01;34mfiles\u001b[0m/        model.pkl   views.py\n","admin_views.pyc  \u001b[01;34mdata\u001b[0m/                      __init__.py   \u001b[01;34mstatic\u001b[0m/     views.pyc\n","C8ud3_vQcw4.mp4  detect.py                  __init__.pyc  \u001b[01;34mtemplates\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NxDa-CvSaSup","colab_type":"text"},"source":["# New Section"]},{"cell_type":"code","metadata":{"id":"BgV5EH4ebQXa","colab_type":"code","outputId":"6620116b-0e31-42f1-b73d-6df6fe8dccf5","executionInfo":{"status":"ok","timestamp":1580444761574,"user_tz":-420,"elapsed":6738,"user":{"displayName":"PIMONPUN CHACHOMPHON","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mADcXHBbJOONF0InL7bXugUnPPUUcbPPNR_eEjaWy4=s64","userId":"14117620575648423760"}},"colab":{"base_uri":"https://localhost:8080/","height":292}},"source":["!pip install flask-ngrok"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting flask-ngrok\n","  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n","Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (1.1.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (2.21.0)\n","Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (0.16.0)\n","Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (2.10.3)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2019.11.28)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (1.24.3)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n","Installing collected packages: flask-ngrok\n","Successfully installed flask-ngrok-0.0.25\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UCs2s3NmbXjz","colab_type":"code","outputId":"1d6334aa-4a4c-49ab-c399-0dbe93396ce7","executionInfo":{"status":"ok","timestamp":1580450742397,"user_tz":-420,"elapsed":2199261,"user":{"displayName":"PIMONPUN CHACHOMPHON","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mADcXHBbJOONF0InL7bXugUnPPUUcbPPNR_eEjaWy4=s64","userId":"14117620575648423760"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from flask_ngrok import run_with_ngrok\n","from flask import Flask\n","from flask import render_template, request, redirect, flash, url_for\n","from werkzeug.utils import secure_filename\n","import os\n","import subprocess\n","import json\n","import pandas as pd\n","import numpy as np\n","import glob\n","import cv2\n","import pickle\n","from sklearn.preprocessing import StandardScaler\n","import shutil\n","\n","\n","app = Flask(__name__)\n","run_with_ngrok(app)   #starts ngrok when the app is run\n","\n","app.config[\"VIDEO_UPLOADS\"] = \"/content/drive/My Drive/DetectConcealGun/ep2/app/files\"\n","app.config[\"ALLOWED_VIDEO_EXTENSIONS\"] = [\"MP4\",\"MOV\",\"AVI\"]\n","\n","\n","\n","def framestoVDO():\n","  path = 'app/files/images/'\n","  img_array = []\n","  for filename in glob.glob(path+'*.jpg'):\n","    img = cv2.imread(filename)\n","    height, width, layers = img.shape\n","    size = (width,height)\n","    img_array.append(img) \n","  out = cv2.VideoWriter('app/files/result.avi', cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n","  for i in range(len(img_array)):\n","    out.write(img_array[i])\n","  out.release()\n","  print(\"it's success, you GREAT!\")\n","\n","def person_box(APIC):\n","    aray = list()\n","    for f in glob.glob('app/files/image/*.jpg'):\n","        aa = (os.path.split(f)[-1])\n","        aray.append(aa)\n","\n","    shutil.rmtree('app/files/images')\n","    os.mkdir('app/files/images')\n","    path = 'app/files/image/'\n","    for i in aray : ##\n","        images = cv2.imread(path+i,cv2.IMREAD_COLOR)\n","\n","        person = APIC[APIC[0]==i]\n","        r =  [1.0,2.0,3.0,4.0,5.0]\n","        #Pose position person /\n","        for m in r :\n","            per = person[person[52] == m]\n","            if len(per) > 0:\n","                #select body point\n","                X_min = int(min(min(per[range(4,52,3)].values.tolist())))-50\n","                X_max = int(max(max(per[range(4,52,3)].values.tolist())))+100\n","                Y_min = int(min(min(per[range(2,52,3)].values.tolist())))-50\n","                Y_max = int(max(max(per[range(2,52,3)].values.tolist())))+100\n","                clas = int(per['Class']) #\n","                if clas == 1:\n","                    color = (0,0,255) #RED\n","                    thickness = 20\n","                    images = cv2.rectangle(images, (X_max,Y_min), (X_min,Y_max), color, thickness)\n","                    scor = float(\"%.4f\"% per['Class_1'])*100\n","                    name = 'Gun'+str(clas)+': '+str(scor)+'%'\n","                    font = cv2.FONT_HERSHEY_SIMPLEX \n","                    fontScale = 2\n","                    # Line thickness of 2 px \n","                    thicknes = 7\n","                    images = cv2.putText(images, name, (X_max,Y_min-20), font, fontScale, color, thicknes, cv2.LINE_AA) \n","                else :\n","                    color = (0, 255, 0) #GREEN\n","                    thickness = 20\n","                    images = cv2.rectangle(images,(X_max,Y_min), (X_min,Y_max), color, thickness)\n","                    scor = float(\"%.4f\"% per['Class_0'])*100\n","                    name = 'None'+str(clas)+': '+str(scor)+'%'\n","                    font = cv2.FONT_HERSHEY_SIMPLEX\n","                    fontScale = 2\n","                    # Line thickness of 2 px \n","                    thicknes = 7\n","                    images = cv2.putText(images, name, (X_max,Y_min-20), font, fontScale, color, thicknes, cv2.LINE_AA)\n","                cv2.imwrite('app/files/images/'+i, images)\n","    framestoVDO()\n","\n","\n","def data_join (file1, file2):\n","  #load Class\n","  Class = pd.read_csv(file1) #2041(Class), 2042(Scores)\n","  #load APIC\n","  APIC = pd.read_csv(file2,header=None) \n","  r =  [1.0,2.0,3.0,4.0,5.0]\n","  m = range(0,5)\n","  A = APIC[52]\n","  B = APIC[52]#*Sores0\n","  C = APIC[52]#*Sores1\n","  for n in m :\n","    di = Class[Class['Unnamed: 0']==n]\n","    if len(di) > 0:\n","      clas = int(di['0_Predict'])\n","      cl = int(di['Unnamed: 0'])\n","      score_0 = float(di['Class_0'])\n","      score_1 = float(di['Class_1'])\n","      if cl == 0:\n","        A = A.replace(1.0,clas)\n","        B = B.replace(1.0,score_0)\n","        C = C.replace(1.0,score_1)\n","      elif cl == 1:\n","        A = A.replace(2.0,clas)\n","        B = B.replace(2.0,score_0)\n","        C = C.replace(2.0,score_1)\n","      elif cl == 2:\n","        A = A.replace(3.0,clas)\n","        B = B.replace(3.0,score_0)\n","        C = C.replace(3.0,score_1)\n","      elif cl == 3:\n","        A = A.replace(4.0,clas)\n","        B = B.replace(4.0,score_0)\n","        C = C.replace(4.0,score_1)\n","      elif cl == 4:\n","        A = A.replace(5.0,clas)\n","        B = B.replace(5.0,score_0)\n","        C = C.replace(5.0,score_1)\n","\n","  APIC['Class'] = A\n","  APIC['Class_0'] = B\n","  APIC['Class_1'] = C\n","  #check person\n","  person = len(Class)\n","  APICto = APIC[APIC[52] <= person]\n","  person_box(APICto)\n","\n","def mode_RF(Data): \n","  #reset index\n","  Data.reset_index(drop=True, inplace=True) \n","  X_test = Data.values.tolist()#dataframe to list\n","  \n","  #Load model\n","  filename = \"app/model.pkl\"\n","  with open(filename, 'rb') as file:\n","    model = pickle.load(file)\n","  \n","  #prediction\n","  y_pred= model.predict(X_test)\n","\n","  # show the inputs and predicted outputs\n","  P_data=list()\n","  for i in range(len(X_test)):\n","    P_out = y_pred[i]\n","    P_data.append(P_out) \n","  # Calling DataFrame constructor on list \n","  P_datadf = pd.DataFrame(P_data) \n","  # check class\n","  Data.reset_index(drop=True, inplace=True)#reset index\n","  Data.reset_index(inplace=True) #set key\n","  P_datadf.reset_index(inplace=True)#set key\n","  # keep the predictions for class \n","  df = Data.join(P_datadf, on='index', how='left', rsuffix='_Predict') #join left\n","  df = df.drop(columns=['index_Predict']) #drop don't select\n","\n","    \n","  #prop each class\n","  prob = model.predict_proba(X_test)\n","  prob_out_df = list()\n","  for i in range(len(X_test)):\n","    prob_out = prob[i]\n","    prob_out_df.append(prob_out) \n","  # Calling DataFrame constructor on list \n","  prob_df = pd.DataFrame(prob_out_df) \n","  prob_df.reset_index(drop=True, inplace=True)#reset index\n","  prob_df.reset_index(inplace=True) #set key\n","  prob_df = prob_df.rename(columns={0: \"Class_0\", 1: \"Class_1\"}) #ChangName\n","  df = df.join(prob_df, on='index', how='left', rsuffix='_')\n","  df = df.drop(columns=['index','index_'])\n","\n","  #Save .CSV\n","  df.to_csv('app/files/result_model_prediction.csv') #save result\n","  data_join ('app/files/result_model_prediction.csv', 'app/files/save_apic.csv')\n","\n","def data_train():\n","  file= 'app/files/Fature_to_Test.csv'\n","  Data = pd.read_csv(file,header=None)\n","  mode_RF(Data)\n","\n","def prepare_idx(idkp):\n","  maxjpg =[]\n","  for key, value in idkp.items():\n","    maxjpg.append(max([int(s) for s in key.split('.') if s.isdigit()]))\n","  maxjpg = max(maxjpg)\n","  print('max.jpg = ',maxjpg,'.jpg')\n","\n","  name_column=['XNose','YNose','XLEye','YLEye','XREye','YREye','XLEar','YLEar','XREar','YREar','XLShoulder','YLShoulder','XRShoulder','YRShoulder','XLElbow','YLElbow','XRElbow','YRElbow','XLWrist','YLWrist','XEWrist','YEWrist','XLHip','YLHip','XRHip','YRHip','XLKnee','YLKnee','XRKnee','YRKnee','XLAnkle','YLAnkle','XRAnkle','YRAnkle']\n","  featvec = list()\n","  for idxn in range(1,6,1) :\n","    # create list name pic .jpg ให้วนลูป\n","    jpglist  = list()\n","    pic = ['%s.jpg']\n","    for f in range(1,maxjpg+1,1): \n","      link = pic[0] % (f)\n","      jpglist.append(link)\n","\n","    frame, keypoints, idx = [], [] , []\n","    for key, value in idkp.items():\n","      picx = idkp[(key)]\n","      for p in picx:\n","        frame.append(key)\n","        keypoints.append(p['keypoints'])\n","        idx.append(p['idx'])\n","        df = pd.DataFrame() # create empty dataframe \n","        df['frame'] = frame\n","        df['keypoints'] = keypoints\n","        df['idx'] = idx\n","        apic = df\n","    \n","    jpglistdf = pd.DataFrame(jpglist, columns=['frame']) # Create jpglist dataframe\n","    pointn = apic[apic['idx'] == (idxn)]\n","    allFrame = pd.merge(jpglistdf , pointn[['frame', 'keypoints']], on='frame', how='left')\n","    # Replace NaN with list [-1,-1,-1, .  .  . ,-1] (51 item totol)\n","    allFrame.loc[allFrame['keypoints'].isnull(),['keypoints']] = allFrame.loc[allFrame['keypoints'].isnull(),'keypoints'].apply(lambda keypoints: [-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1])\n","    # Keypoint\n","    kpall = allFrame['keypoints']\n","    # remove c \n","    keypointls = list()\n","    for frm in kpall:\n","      frm = [round(i,3) for i in frm]  # convert a list into list with 3 decimal places\n","      for i in frm:\n","        if i <= 1 and i >= 0 :\n","            frm.remove(i)\n","      keypointls.append(frm)\n","\n","    # convert list to array\n","    keypointar = np.asarray(keypointls)\n","\n","    #ปรับค่า X,Y Nose\n","    arrayper = keypointar\n","    X_Zero = arrayper[:,0] #X point Zero\n","    Y_Zero = arrayper[:,1] #Y point Zero\n","    l=list()\n","    for i in range(0, 34):\n","      if(i%2) == 0:\n","        A = abs(arrayper[:,i] - X_Zero)\n","      else:\n","        A = abs(arrayper[:,i] - Y_Zero)\n","      l.append(A)\n","\n","    #Z Score\n","    \n","    scaler = StandardScaler()\n","    scaler.fit(l)\n","    lstand = scaler.transform(l)\n","    datalistdf = pd.DataFrame(lstand, name_column)\n","    df = datalistdf.T\n","\n","    #กรณี มากกว่า 60 เฟรม จะเริ่มเก็บจากเฟรมสุดท้าย\n","    (naa,nbb) = lstand.shape\n","    D1 = list()\n","    for r in range(0,34):\n","      for t in range(nbb-60,nbb):\n","        dat1 = lstand[r,t]\n","        D1.append(dat1)\n","    datalistdf1 = pd.DataFrame(D1)\n","    df1 = datalistdf1.T\n","    df2 = df.values.tolist()\n","\n","    #กรณีที่จับได้น้อยกว่า 50%\n","    ccv0 = 0\n","    for cv1 in df2:\n","      for cv0 in cv1:\n","        if cv0 == 0:\n","          ccv0 = ccv0 + 1\n","    if ccv0 < 1020:\n","      featvec.append(df1)\n","  featvec2 = pd.concat(featvec)\n","  np.savetxt('app/files/Fature_to_Test.csv', featvec2,delimiter=',' )\n","  np.savetxt('app/files/save_apic.csv',apic,fmt=['%s','%s', '%f'],delimiter=',')\n","  data_train()\n","\n","def read_json(): #read json file\n","  with open('app/files/alphapose-results-forvis-tracked.json','r') as myfile:\n","    data = myfile.read()\n","    obj = json.loads(data)\n","    prepare_idx(obj)\n","\n","\n","def  get_poseflow(video_input):\n","  shutil.rmtree('files/image')\n","  os.mkdir(\"files/image\")\n","  !ffmpeg  -i $video_input -r 30 files/image/%d.jpg    #Extract images\n","\n","  shutil.rmtree('files/Outimages')\n","  os.mkdir (\"files/Outimages\")\n","  !pip install -q youtube-dl visdom\n","  os.chdir( \"files/AlphaPose\" )\n","  !python3 demo.py --sp --indir ../image/ --outdir ../.\n","  !pip2 install munkres==1.0.12   #poseflow\n","  os.chdir('/content/drive/My Drive/DetectConcealGun/ep2/app/files')\n","  !python2  AlphaPose/PoseFlow/tracker-general.py --imgdir image/ --in_json alphapose-results.json --out_json alphapose-results-forvis-tracked.json --visdir Outimages/\n","  os.chdir('/content/drive/My Drive/DetectConcealGun/ep2')\n","  read_json()\n","\n","def get_length(filename):\n","  result = subprocess.run([\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\", \"-of\", \"default=noprint_wrappers=1:nokey=1\", filename], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n","  print('Video length : ' ,float(result.stdout))\n","  if float(result.stdout) < 2:\n","    print (\"Please upload your video less than 2 second\")\n","  elif float(result.stdout) > 3.5 :\n","    print (\"Sorry this video is more than 2 second video\")\n","  else :\n","    get_poseflow(filename)\n","\n","def main(videoName):\n","  os.chdir(\"/content/drive/My Drive/DetectConcealGun/ep2/app/\")\n","  # videoName = str(input(\"Enter Video name : \"))\n","  videoName = 'C8ud3_vQcw4.mp4'\n","  get_length(videoName)\n","\n","\n","\n","def allowed_video(filename):\n","    if not \".\" in filename:\n","        return False\n","    ext = filename.rsplit(\".\", 1)[1]\n","    if ext.upper() in app.config[\"ALLOWED_VIDEO_EXTENSIONS\"]:\n","        return True\n","    else:\n","        return False\n","\n","@app.route(\"/\", methods=[\"GET\", \"POST\"])\n","def upload_video():\n","    if request.method == \"POST\":\n","        if request.files:\n","            video = request.files[\"video\"]\n","            if video.filename == \"\":\n","                # flash(\"No file\", \"warning\")\n","                return redirect(request.url)\n","            if allowed_video(video.filename):\n","                filename = secure_filename(video.filename)\n","                video.save(os.path.join(app.config[\"VIDEO_UPLOADS\"], filename))\n","                # flash(\"Video uploaded\", \"success\")\n","                main(filename)\n","                return redirect(request.url)\n","                # return redirect(url_for(\"result_detect\",filename=filename))\n","\n","            else:\n","                # flash(\"That file extension is not allowed\", \"danger\")\n","                return redirect(request.url)\n","    return render_template(\"public/upload_video.html\")\n","\n","\n","\n","\n","@app.route(\"/about\")\n","def about():\n","    return render_template(\"public/about.html\")\n","  \n","\n","\n","  \n","app.run()"],"execution_count":20,"outputs":[{"output_type":"stream","text":[" * Serving Flask app \"__main__\" (lazy loading)\n"," * Environment: production\n","   WARNING: This is a development server. Do not use it in a production deployment.\n","   Use a production WSGI server instead.\n"," * Debug mode: off\n"],"name":"stdout"},{"output_type":"stream","text":[" * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"],"name":"stderr"},{"output_type":"stream","text":[" * Running on http://0397b780.ngrok.io\n"," * Traffic stats available on http://127.0.0.1:4040\n"],"name":"stdout"},{"output_type":"stream","text":["127.0.0.1 - - [31/Jan/2020 05:29:11] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [31/Jan/2020 05:29:12] \"\u001b[37mGET /static/css/style.css HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [31/Jan/2020 05:29:12] \"\u001b[37mGET /static/js/app.js HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [31/Jan/2020 05:29:12] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"],"name":"stderr"},{"output_type":"stream","text":["Video length :  2.0\n","ffmpeg version 3.4.6-0ubuntu0.18.04.1 Copyright (c) 2000-2019 the FFmpeg developers\n","  built with gcc 7 (Ubuntu 7.3.0-16ubuntu3)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.18.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n","  libavutil      55. 78.100 / 55. 78.100\n","  libavcodec     57.107.100 / 57.107.100\n","  libavformat    57. 83.100 / 57. 83.100\n","  libavdevice    57. 10.100 / 57. 10.100\n","  libavfilter     6.107.100 /  6.107.100\n","  libavresample   3.  7.  0 /  3.  7.  0\n","  libswscale      4.  8.100 /  4.  8.100\n","  libswresample   2.  9.100 /  2.  9.100\n","  libpostproc    54.  7.100 / 54.  7.100\n","Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'C8ud3_vQcw4.mp4':\n","  Metadata:\n","    major_brand     : mp42\n","    minor_version   : 0\n","    compatible_brands: mp41isom\n","    creation_time   : 2019-12-16T02:47:42.000000Z\n","  Duration: 00:00:02.00, start: 0.000000, bitrate: 1924 kb/s\n","    Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p, 1920x1080 [SAR 1:1 DAR 16:9], 1920 kb/s, 30 fps, 30 tbr, 30k tbn, 60 tbc (default)\n","    Metadata:\n","      creation_time   : 2020-01-14T03:52:14.000000Z\n","      handler_name    : VideoHandler\n","      encoder         : AVC Coding\n","Stream mapping:\n","  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n","Press [q] to stop, [?] for help\n","\u001b[1;34m[swscaler @ 0x559aa6204000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n","\u001b[0mOutput #0, image2, to 'files/image/%d.jpg':\n","  Metadata:\n","    major_brand     : mp42\n","    minor_version   : 0\n","    compatible_brands: mp41isom\n","    encoder         : Lavf57.83.100\n","    Stream #0:0(und): Video: mjpeg, yuvj420p(pc), 1920x1080 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 30 fps, 30 tbn, 30 tbc (default)\n","    Metadata:\n","      creation_time   : 2020-01-14T03:52:14.000000Z\n","      handler_name    : VideoHandler\n","      encoder         : Lavc57.107.100 mjpeg\n","    Side data:\n","      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n","frame=   60 fps= 37 q=24.8 Lsize=N/A time=00:00:02.00 bitrate=N/A speed=1.24x    \n","video:6275kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n","\u001b[K     |████████████████████████████████| 1.8MB 9.5MB/s \n","\u001b[K     |████████████████████████████████| 686kB 70.9MB/s \n","\u001b[K     |████████████████████████████████| 204kB 58.8MB/s \n","\u001b[?25h  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Loading YOLO model..\n","Loading pose model from ./models/sppe/duc_se.pth\n","100% 60/60 [00:04<00:00, 14.17it/s]\n","===========================> Finish Model Running.\n","Collecting munkres==1.0.12\n","  Downloading https://files.pythonhosted.org/packages/ea/f3/21d3c23017ba987e77286c5f7b6334366777919ced67f6bb9d48f5f5936c/munkres-1.0.12-py2.py3-none-any.whl\n","Installing collected packages: munkres\n","Successfully installed munkres-1.0.12\n","Start loading json file...\n","\n","100% 60/60 [00:01<00:00, 37.13it/s]\n","Start pose tracking...\n","\n","100% 59/59 [02:01<00:00,  2.03s/it]\n","This video contains 4 people.\n","Export tracking results to json...\n","\n","100% 60/60 [00:00<00:00, 53193.46it/s]\n","Start visualization...\n","\n","100% 60/60 [00:55<00:00,  1.10it/s]\n","max.jpg =  60 .jpg\n"],"name":"stdout"},{"output_type":"stream","text":["[2020-01-31 05:33:36,568] ERROR in app: Exception on / [POST]\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 2446, in wsgi_app\n","    response = self.full_dispatch_request()\n","  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1951, in full_dispatch_request\n","    rv = self.handle_user_exception(e)\n","  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1820, in handle_user_exception\n","    reraise(exc_type, exc_value, tb)\n","  File \"/usr/local/lib/python3.6/dist-packages/flask/_compat.py\", line 39, in reraise\n","    raise value\n","  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1949, in full_dispatch_request\n","    rv = self.dispatch_request()\n","  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1935, in dispatch_request\n","    return self.view_functions[rule.endpoint](**req.view_args)\n","  File \"<ipython-input-20-8a2d395c69e1>\", line 342, in upload_video\n","    main(filename)\n","  File \"<ipython-input-20-8a2d395c69e1>\", line 317, in main\n","    get_length(videoName)\n","  File \"<ipython-input-20-8a2d395c69e1>\", line 311, in get_length\n","    get_poseflow(filename)\n","  File \"<ipython-input-20-8a2d395c69e1>\", line 301, in get_poseflow\n","    read_json()\n","  File \"<ipython-input-20-8a2d395c69e1>\", line 284, in read_json\n","    prepare_idx(obj)\n","  File \"<ipython-input-20-8a2d395c69e1>\", line 278, in prepare_idx\n","    data_train()\n","  File \"<ipython-input-20-8a2d395c69e1>\", line 185, in data_train\n","    mode_RF(Data)\n","  File \"<ipython-input-20-8a2d395c69e1>\", line 180, in mode_RF\n","    data_join ('app/files/result_model_prediction.csv', 'app/files/save_apic.csv')\n","  File \"<ipython-input-20-8a2d395c69e1>\", line 133, in data_join\n","    person_box(APICto)\n","  File \"<ipython-input-20-8a2d395c69e1>\", line 45, in person_box\n","    shutil.rmtree('app/file/images')\n","  File \"/usr/lib/python3.6/shutil.py\", line 477, in rmtree\n","    onerror(os.lstat, path, sys.exc_info())\n","  File \"/usr/lib/python3.6/shutil.py\", line 475, in rmtree\n","    orig_st = os.lstat(path)\n","FileNotFoundError: [Errno 2] No such file or directory: 'app/file/images'\n","127.0.0.1 - - [31/Jan/2020 05:33:36] \"\u001b[1m\u001b[35mPOST / HTTP/1.1\u001b[0m\" 500 -\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"JyMYwwY46nAm","colab_type":"text"},"source":["# DETECT"]},{"cell_type":"code","metadata":{"id":"8qDIRj596pRr","colab_type":"code","colab":{}},"source":["import os\n","import subprocess\n","import json\n","import pandas as pd\n","import numpy as np\n","import glob\n","import cv2\n","import pickle\n","from sklearn.preprocessing import StandardScaler\n","import shutil\n","\n","def framestoVDO():\n","  path = 'app/files/images/'\n","  img_array = []\n","  for filename in glob.glob(path+'*.jpg'):\n","    img = cv2.imread(filename)\n","    height, width, layers = img.shape\n","    size = (width,height)\n","    img_array.append(img) \n","  out = cv2.VideoWriter('app/files/result.avi', cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n","  for i in range(len(img_array)):\n","    out.write(img_array[i])\n","  out.release()\n","  print(\"it's success, you GREAT!\")\n","\n","def person_box(APIC):\n","    aray = list()\n","    for f in glob.glob('app/files/image/*.jpg'):\n","        aa = (os.path.split(f)[-1])\n","        aray.append(aa)\n","\n","    shutil.rmtree('app/file/images')\n","    os.mkdir('app/file/images')\n","    path = 'app/files/image/'\n","    for i in aray : ##\n","        images = cv2.imread(path+i,cv2.IMREAD_COLOR)\n","\n","        person = APIC[APIC[0]==i]\n","        r =  [1.0,2.0,3.0,4.0,5.0]\n","        #Pose position person /\n","        for m in r :\n","            per = person[person[52] == m]\n","            if len(per) > 0:\n","                #select body point\n","                X_min = int(min(min(per[range(4,52,3)].values.tolist())))-50\n","                X_max = int(max(max(per[range(4,52,3)].values.tolist())))+100\n","                Y_min = int(min(min(per[range(2,52,3)].values.tolist())))-50\n","                Y_max = int(max(max(per[range(2,52,3)].values.tolist())))+100\n","                clas = int(per['Class']) #\n","                if clas == 1:\n","                    color = (0,0,255) #RED\n","                    thickness = 20\n","                    images = cv2.rectangle(images, (X_max,Y_min), (X_min,Y_max), color, thickness)\n","                    scor = float(\"%.4f\"% per['Class_1'])*100\n","                    name = 'Gun'+str(clas)+': '+str(scor)+'%'\n","                    font = cv2.FONT_HERSHEY_SIMPLEX \n","                    fontScale = 2\n","                    # Line thickness of 2 px \n","                    thicknes = 7\n","                    images = cv2.putText(images, name, (X_max,Y_min-20), font, fontScale, color, thicknes, cv2.LINE_AA) \n","                else :\n","                    color = (0, 255, 0) #GREEN\n","                    thickness = 20\n","                    images = cv2.rectangle(images,(X_max,Y_min), (X_min,Y_max), color, thickness)\n","                    scor = float(\"%.4f\"% per['Class_0'])*100\n","                    name = 'None'+str(clas)+': '+str(scor)+'%'\n","                    font = cv2.FONT_HERSHEY_SIMPLEX\n","                    fontScale = 2\n","                    # Line thickness of 2 px \n","                    thicknes = 7\n","                    images = cv2.putText(images, name, (X_max,Y_min-20), font, fontScale, color, thicknes, cv2.LINE_AA)\n","                cv2.imwrite('app/files/images/'+i, images)\n","    framestoVDO()\n","\n","\n","def data_join (file1, file2):\n","  #load Class\n","  Class = pd.read_csv(file1) #2041(Class), 2042(Scores)\n","  #load APIC\n","  APIC = pd.read_csv(file2,header=None) \n","  r =  [1.0,2.0,3.0,4.0,5.0]\n","  m = range(0,5)\n","  A = APIC[52]\n","  B = APIC[52]#*Sores0\n","  C = APIC[52]#*Sores1\n","  for n in m :\n","    di = Class[Class['Unnamed: 0']==n]\n","    if len(di) > 0:\n","      clas = int(di['0_Predict'])\n","      cl = int(di['Unnamed: 0'])\n","      score_0 = float(di['Class_0'])\n","      score_1 = float(di['Class_1'])\n","      if cl == 0:\n","        A = A.replace(1.0,clas)\n","        B = B.replace(1.0,score_0)\n","        C = C.replace(1.0,score_1)\n","      elif cl == 1:\n","        A = A.replace(2.0,clas)\n","        B = B.replace(2.0,score_0)\n","        C = C.replace(2.0,score_1)\n","      elif cl == 2:\n","        A = A.replace(3.0,clas)\n","        B = B.replace(3.0,score_0)\n","        C = C.replace(3.0,score_1)\n","      elif cl == 3:\n","        A = A.replace(4.0,clas)\n","        B = B.replace(4.0,score_0)\n","        C = C.replace(4.0,score_1)\n","      elif cl == 4:\n","        A = A.replace(5.0,clas)\n","        B = B.replace(5.0,score_0)\n","        C = C.replace(5.0,score_1)\n","\n","  APIC['Class'] = A\n","  APIC['Class_0'] = B\n","  APIC['Class_1'] = C\n","  #check person\n","  person = len(Class)\n","  APICto = APIC[APIC[52] <= person]\n","  person_box(APICto)\n","\n","def mode_RF(Data): \n","  #reset index\n","  Data.reset_index(drop=True, inplace=True) \n","  X_test = Data.values.tolist()#dataframe to list\n","  \n","  #Load model\n","  filename = \"app/model.pkl\"\n","  with open(filename, 'rb') as file:\n","    model = pickle.load(file)\n","  \n","  #prediction\n","  y_pred= model.predict(X_test)\n","\n","  # show the inputs and predicted outputs\n","  P_data=list()\n","  for i in range(len(X_test)):\n","    P_out = y_pred[i]\n","    P_data.append(P_out) \n","  # Calling DataFrame constructor on list \n","  P_datadf = pd.DataFrame(P_data) \n","  # check class\n","  Data.reset_index(drop=True, inplace=True)#reset index\n","  Data.reset_index(inplace=True) #set key\n","  P_datadf.reset_index(inplace=True)#set key\n","  # keep the predictions for class \n","  df = Data.join(P_datadf, on='index', how='left', rsuffix='_Predict') #join left\n","  df = df.drop(columns=['index_Predict']) #drop don't select\n","\n","    \n","  #prop each class\n","  prob = model.predict_proba(X_test)\n","  prob_out_df = list()\n","  for i in range(len(X_test)):\n","    prob_out = prob[i]\n","    prob_out_df.append(prob_out) \n","  # Calling DataFrame constructor on list \n","  prob_df = pd.DataFrame(prob_out_df) \n","  prob_df.reset_index(drop=True, inplace=True)#reset index\n","  prob_df.reset_index(inplace=True) #set key\n","  prob_df = prob_df.rename(columns={0: \"Class_0\", 1: \"Class_1\"}) #ChangName\n","  df = df.join(prob_df, on='index', how='left', rsuffix='_')\n","  df = df.drop(columns=['index','index_'])\n","\n","  #Save .CSV\n","  df.to_csv('app/files/result_model_prediction.csv') #save result\n","  data_join ('app/files/result_model_prediction.csv', 'app/files/save_apic.csv')\n","\n","def data_train():\n","  file= 'app/files/Fature_to_Test.csv'\n","  Data = pd.read_csv(file,header=None)\n","  mode_RF(Data)\n","\n","def prepare_idx(idkp):\n","  maxjpg =[]\n","  for key, value in idkp.items():\n","    maxjpg.append(max([int(s) for s in key.split('.') if s.isdigit()]))\n","  maxjpg = max(maxjpg)\n","  print('max.jpg = ',maxjpg,'.jpg')\n","\n","  name_column=['XNose','YNose','XLEye','YLEye','XREye','YREye','XLEar','YLEar','XREar','YREar','XLShoulder','YLShoulder','XRShoulder','YRShoulder','XLElbow','YLElbow','XRElbow','YRElbow','XLWrist','YLWrist','XEWrist','YEWrist','XLHip','YLHip','XRHip','YRHip','XLKnee','YLKnee','XRKnee','YRKnee','XLAnkle','YLAnkle','XRAnkle','YRAnkle']\n","  featvec = list()\n","  for idxn in range(1,6,1) :\n","    # create list name pic .jpg ให้วนลูป\n","    jpglist  = list()\n","    pic = ['%s.jpg']\n","    for f in range(1,maxjpg+1,1): \n","      link = pic[0] % (f)\n","      jpglist.append(link)\n","\n","    frame, keypoints, idx = [], [] , []\n","    for key, value in idkp.items():\n","      picx = idkp[(key)]\n","      for p in picx:\n","        frame.append(key)\n","        keypoints.append(p['keypoints'])\n","        idx.append(p['idx'])\n","        df = pd.DataFrame() # create empty dataframe \n","        df['frame'] = frame\n","        df['keypoints'] = keypoints\n","        df['idx'] = idx\n","        apic = df\n","    \n","    jpglistdf = pd.DataFrame(jpglist, columns=['frame']) # Create jpglist dataframe\n","    pointn = apic[apic['idx'] == (idxn)]\n","    allFrame = pd.merge(jpglistdf , pointn[['frame', 'keypoints']], on='frame', how='left')\n","    # Replace NaN with list [-1,-1,-1, .  .  . ,-1] (51 item totol)\n","    allFrame.loc[allFrame['keypoints'].isnull(),['keypoints']] = allFrame.loc[allFrame['keypoints'].isnull(),'keypoints'].apply(lambda keypoints: [-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1])\n","    # Keypoint\n","    kpall = allFrame['keypoints']\n","    # remove c \n","    keypointls = list()\n","    for frm in kpall:\n","      frm = [round(i,3) for i in frm]  # convert a list into list with 3 decimal places\n","      for i in frm:\n","        if i <= 1 and i >= 0 :\n","            frm.remove(i)\n","      keypointls.append(frm)\n","\n","    # convert list to array\n","    keypointar = np.asarray(keypointls)\n","\n","    #ปรับค่า X,Y Nose\n","    arrayper = keypointar\n","    X_Zero = arrayper[:,0] #X point Zero\n","    Y_Zero = arrayper[:,1] #Y point Zero\n","    l=list()\n","    for i in range(0, 34):\n","      if(i%2) == 0:\n","        A = abs(arrayper[:,i] - X_Zero)\n","      else:\n","        A = abs(arrayper[:,i] - Y_Zero)\n","      l.append(A)\n","\n","    #Z Score\n","    \n","    scaler = StandardScaler()\n","    scaler.fit(l)\n","    lstand = scaler.transform(l)\n","    datalistdf = pd.DataFrame(lstand, name_column)\n","    df = datalistdf.T\n","\n","    #กรณี มากกว่า 60 เฟรม จะเริ่มเก็บจากเฟรมสุดท้าย\n","    (naa,nbb) = lstand.shape\n","    D1 = list()\n","    for r in range(0,34):\n","      for t in range(nbb-60,nbb):\n","        dat1 = lstand[r,t]\n","        D1.append(dat1)\n","    datalistdf1 = pd.DataFrame(D1)\n","    df1 = datalistdf1.T\n","    df2 = df.values.tolist()\n","\n","    #กรณีที่จับได้น้อยกว่า 50%\n","    ccv0 = 0\n","    for cv1 in df2:\n","      for cv0 in cv1:\n","        if cv0 == 0:\n","          ccv0 = ccv0 + 1\n","    if ccv0 < 1020:\n","      featvec.append(df1)\n","  featvec2 = pd.concat(featvec)\n","  np.savetxt('app/files/Fature_to_Test.csv', featvec2,delimiter=',' )\n","  np.savetxt('app/files/save_apic.csv',apic,fmt=['%s','%s', '%f'],delimiter=',')\n","  data_train()\n","\n","def read_json(): #read json file\n","  with open('app/files/alphapose-results-forvis-tracked.json','r') as myfile:\n","    data = myfile.read()\n","    obj = json.loads(data)\n","    prepare_idx(obj)\n","\n","\n","def  get_poseflow(video_input):\n","  shutil.rmtree('files/image')\n","  os.mkdir(\"files/image\")\n","  !ffmpeg  -i $video_input -r 30 files/image/%d.jpg    #Extract images\n","\n","  shutil.rmtree('files/Outimages')\n","  os.mkdir (\"files/Outimages\")\n","  !pip install -q youtube-dl visdom\n","  os.chdir( \"files/AlphaPose\" )\n","  !python3 demo.py --sp --indir ../image/ --outdir ../.\n","  !pip2 install munkres==1.0.12   #poseflow\n","  os.chdir('/content/gdrive/My Drive/DETECT/TEST PROJECT/app/files')\n","  !python2  AlphaPose/PoseFlow/tracker-general.py --imgdir image/ --in_json alphapose-results.json --out_json alphapose-results-forvis-tracked.json --visdir Outimages/\n","  os.chdir('/content/gdrive/My Drive/DETECT/TEST PROJECT')\n","  read_json()\n","\n","def get_length(filename):\n","  result = subprocess.run([\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\", \"-of\", \"default=noprint_wrappers=1:nokey=1\", filename], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n","  print('Video length : ' ,float(result.stdout))\n","  if float(result.stdout) < 2:\n","    print (\"Please upload your video less than 2 second\")\n","  elif float(result.stdout) > 3.5 :\n","    print (\"Sorry this video is more than 2 second video\")\n","  else :\n","    get_poseflow(filename)\n","\n","def main():\n","  os.chdir(\"/content/gdrive/My Drive/DETECT/TEST PROJECT/app\")\n","  # videoName = str(input(\"Enter Video name : \"))\n","  videoName = 'C8ud3_vQcw4.mp4'\n","  get_length(videoName)\n","\n","\n","main()\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"49OOfwNy9lRW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"1048397a-76f2-4f01-e972-a05eae801f30","executionInfo":{"status":"ok","timestamp":1580446673076,"user_tz":-420,"elapsed":1169,"user":{"displayName":"PIMONPUN CHACHOMPHON","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mADcXHBbJOONF0InL7bXugUnPPUUcbPPNR_eEjaWy4=s64","userId":"14117620575648423760"}}},"source":["os.getcwd()"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/DetectConcealGun/ep2/app'"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"POODmwesmWX0","colab_type":"code","outputId":"93b997d2-6a71-4e3b-da7b-27051654887f","colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["# import os\n","# from os.path import exists, join, basename, splitext\n","# import sys\n","# import matplotlib\n","# import matplotlib.pylab as plt\n","\n","# def download_from_google_drive(file_id, file_name):\n","#   # download a file from the Google Drive link\n","#   !rm -f ./cookie\n","#   !curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id=$file_id\" > /dev/null\n","#   confirm_text = !awk '/download/ {print $NF}' ./cookie\n","#   confirm_text = confirm_text[0]\n","#   !curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=$confirm_text&id=$file_id\" -o $file_name\n","  \n","# def dl_pretrain_models(projectname):\n","#   pretrained_model_path = join(projectname, 'models/sppe/duc_se.pth')\n","#   if not exists(pretrained_model_path):\n","#     # download the pretrained model\n","#     download_from_google_drive('1OPORTWB2cwd5YTVBX-NE8fsauZJWsrtW', pretrained_model_path)\n","#   yolo_pretrained_model_path = join(projectname, 'models/yolo/yolov3-spp.weights')\n","#   if not exists(yolo_pretrained_model_path):\n","#     # download the YOLO weights\n","#     download_from_google_drive('1D47msNOOiJKvPOXlnpyzdKA3k6E97NTC', yolo_pretrained_model_path) \n","\n","# def install_alphapose():\n","#   os.chdir( \"app/files\" )\n","#   git_repo_url = 'https://github.com/MVIG-SJTU/AlphaPose.git'\n","#   project_name = splitext(basename(git_repo_url))[0]\n","#   if not exists(project_name):\n","#     # clone and install dependencies\n","#     !git clone -q -b pytorch --depth 1 $git_repo_url\n","#     !cd $project_name && pip install -q -r requirements.txt\n","#     !pip install -q youtube-dl visdom\n","#   sys.path.append(project_name)\n","#   plt.rcParams[\"axes.grid\"] = False\n","#   dl_pretrain_models(project_name)\n","\n","\n","# install_alphapose()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 484.0MB 37kB/s \n","\u001b[K     |████████████████████████████████| 686kB 56.1MB/s \n","\u001b[31mERROR: Could not find a version that satisfies the requirement ntpath (from -r requirements.txt (line 9)) (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for ntpath (from -r requirements.txt (line 9))\u001b[0m\n","\u001b[K     |████████████████████████████████| 1.8MB 4.5MB/s \n","\u001b[K     |████████████████████████████████| 204kB 35.4MB/s \n","\u001b[?25h  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   388    0   388    0     0   1739      0 --:--:-- --:--:-- --:--:--  1739\n","100  227M    0  227M    0     0  66.0M      0 --:--:--  0:00:03 --:--:-- 75.4M\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   388    0   388    0     0   1813      0 --:--:-- --:--:-- --:--:--  1813\n","100  240M    0  240M    0     0  67.5M      0 --:--:--  0:00:03 --:--:-- 81.1M\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bR3_7lg7P5rS","colab_type":"code","outputId":"fff5eb3b-05ca-4529-b004-f8d850ab56c8","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd .."],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/DetectingConcealedGun\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R9CAdBsvVE6h","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}